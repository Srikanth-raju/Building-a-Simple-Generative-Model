{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1cc58e",
   "metadata": {},
   "source": [
    "# TEAM TRINITY - Group 1\n",
    "\n",
    "## Team Members: \n",
    "\n",
    "#### SAI SRIKANTH RAJU  C0846551\n",
    "#### SHWETA YADAV          C0854479\n",
    "#### KATLEEN ORATA        C0848019\n",
    "#### DOMINIC MONROE     C0832828\n",
    "#### PRANAY GURUNG      C0841092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30742344",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebd1e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: torch==2.0.0 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision) (4.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from torch==2.0.0->torchvision) (1.10.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rsshrikantth\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#Installing Torchvision\n",
    "!pip install torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b700d9e",
   "metadata": {},
   "source": [
    "### TASK:1 Importing the dataset and cleaning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b11215b",
   "metadata": {},
   "source": [
    "BOOK: The Great Gatsby by F. Scott Fitzgerald\n",
    "\n",
    "https://www.gutenberg.org/ebooks/64317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06761de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the neccessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6ccc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# read file contents into a string variable\n",
    "with open('thegreatgatsby.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# define stop word pattern\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_word_pattern = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "\n",
    "# remove stop words using regular expression\n",
    "clean_text = re.sub(stop_word_pattern, '', text)\n",
    "\n",
    "# write modified string back to file\n",
    "with open('thegreatgatsby_clean.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d772ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"thegreatgatsby_clean.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848c6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba3e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters are ::  223256\n",
      "Total Vocab are ::  69\n",
      "Total Patterns are ::  223156\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters are :: \", n_chars)\n",
    "print(\"Total Vocab are :: \", n_vocab)\n",
    " \n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns are :: \", n_patterns)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb694f",
   "metadata": {},
   "source": [
    "### TASK 2: Building Single Layer LSTM and Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b1b672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RSShrikantth\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: Cross-entropy: 628924.9375\n",
      "Epoch  1: Cross-entropy: 613747.6875\n",
      "Epoch  2: Cross-entropy: 601784.0625\n",
      "Epoch  3: Cross-entropy: 590165.3125\n",
      "Epoch  4: Cross-entropy: 580016.6250\n",
      "Epoch  5: Cross-entropy: 570917.5625\n",
      "Epoch  6: Cross-entropy: 563208.1250\n",
      "Epoch  7: Cross-entropy: 557841.4375\n",
      "Epoch  8: Cross-entropy: 548569.3750\n",
      "Epoch  9: Cross-entropy: 542162.3125\n",
      "Epoch  10: Cross-entropy: 535419.8125\n",
      "Epoch  11: Cross-entropy: 528351.3750\n",
      "Epoch  12: Cross-entropy: 522465.7500\n",
      "Epoch  13: Cross-entropy: 515493.3750\n",
      "Epoch  14: Cross-entropy: 511169.8438\n",
      "Epoch  15: Cross-entropy: 507609.0938\n",
      "Epoch  16: Cross-entropy: 500199.7500\n",
      "Epoch  17: Cross-entropy: 494572.5625\n",
      "Epoch  18: Cross-entropy: 489218.3125\n",
      "Epoch  19: Cross-entropy: 484680.7812\n",
      "Epoch  20: Cross-entropy: 480478.2812\n",
      "Epoch  21: Cross-entropy: 476048.6250\n",
      "Epoch  22: Cross-entropy: 483479.6250\n",
      "Epoch  23: Cross-entropy: 469728.0625\n",
      "Epoch  24: Cross-entropy: 465089.9688\n",
      "Epoch  25: Cross-entropy: 462463.0625\n",
      "Epoch  26: Cross-entropy: 464050.5312\n",
      "Epoch  27: Cross-entropy: 456861.4375\n",
      "Epoch  28: Cross-entropy: 454810.7812\n",
      "Epoch  29: Cross-entropy: 450858.5312\n",
      "Epoch  30: Cross-entropy: 446542.4688\n",
      "Epoch  31: Cross-entropy: 447665.8125\n",
      "Epoch  32: Cross-entropy: 443179.4688\n",
      "Epoch  33: Cross-entropy: 441298.9375\n",
      "Epoch  34: Cross-entropy: 439277.6250\n",
      "Epoch  35: Cross-entropy: 440654.4062\n",
      "Epoch  36: Cross-entropy: 434939.8125\n",
      "Epoch  37: Cross-entropy: 432557.2188\n",
      "Epoch  38: Cross-entropy: 430904.0000\n",
      "Epoch  39: Cross-entropy: 431300.0000\n",
      "Epoch  40: Cross-entropy: 428173.1875\n",
      "Epoch  41: Cross-entropy: 426489.0312\n",
      "Epoch  42: Cross-entropy: 430747.4375\n",
      "Epoch  43: Cross-entropy: 426276.6875\n",
      "Epoch  44: Cross-entropy: 427810.3750\n"
     ]
    }
   ],
   "source": [
    "#The following code is for training a character-level language model using PyTorch.\n",
    "#Reshaping the input data X to be [samples, time steps, features] and convert it to a PyTorch tensor of float32 data type.\n",
    "#Scaling the input data by dividing it by the number of unique characters (n_vocab).\n",
    "#Converting the target data Y to a PyTorch tensor.\n",
    "\n",
    "X = torch.tensor(dataX, dtype=torch.float32).reshape(n_patterns, seq_length, 1)\n",
    "X = X / float(n_vocab)\n",
    "y = torch.tensor(dataY)\n",
    "\n",
    "#Defining a class for the LSTM-based model that inherits from PyTorch's nn.Module class.\n",
    "#The model consists of a single LSTM layer with 256 hidden units, a dropout layer, and a linear layer to produce the output.\n",
    "#The forward method defines the forward pass of the model.\n",
    "\n",
    "class CharModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True, dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # take only the last output\n",
    "        x = x[:, -1, :]\n",
    "        # produce output\n",
    "        x = self.linear(self.dropout(x))\n",
    "        return x\n",
    "    \n",
    "#Setting the number of training epochs and the batch size, and create an instance of the CharModel class.\n",
    "\n",
    "n_epochs = 45\n",
    "batch_size = 128\n",
    "model = CharModel()\n",
    "\n",
    "#Defining the optimizer and the loss function.\n",
    "#Using Adam optimizer with the default learning rate.\n",
    "#Using cross-entropy loss with sum reduction.\n",
    "#Creating a data loader for the input and target data, with shuffling and batching.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "#Calculate the model's predictions, the loss, and perform backpropagation and gradient descent to update the model's parameters.\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss += loss_fn(y_pred, y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch  %d: Cross-entropy: %.4f\" % (epoch, loss))\n",
    "        \n",
    "#Save the best performing model and the character-to-integer mapping in a PyTorch state dictionary format.\n",
    "\n",
    "torch.save([best_model, char_to_int], \"singlebest-char.pth\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ca994",
   "metadata": {},
   "source": [
    "## Generation of Prompt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6019ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: ' “this fellow  worked   whole thing. it’  \n",
      "us,    dominant race,  watch     races \n",
      " control  things.', Perplexity score :: 0.17\n",
      "Prompt 2: 'ople\n",
      "begin  sneering  family life  family institutions,  next\n",
      "’ throw everything overboard   interma', Perplexity score :: 0.17\n",
      "Prompt 3: '  house\n",
      " ,    boat  looked like  house   moved secretly\n",
      "    long island shore. just   inventions  \n",
      "s', Perplexity score :: 0.17\n",
      "Prompt 4: 'evening  made  lightheaded  happy; i think i walked  \n",
      "deep sleep  i entered  front door. so i ’ know', Perplexity score :: 0.17\n",
      "Prompt 5: 'e  sudden intimation    content   alone— stretched\n",
      "  arms toward  dark water   curious way, , far  i', Perplexity score :: 0.17\n",
      "Prompt 6: '   brought    \n",
      "pool. he stopped   garage   pneumatic mattress  \n",
      "amused  guests   summer,   chauffeur', Perplexity score :: 0.17\n",
      "Prompt 7: 'ws downstairs   pink glow  daisy’ room   ground\n",
      "floor.\n",
      "\n",
      "“you wait ,” i said. “i’ see  ’  sign  \n",
      "comm', Perplexity score :: 0.17\n",
      "Prompt 8: 'ware\n",
      "  superiority   bored, sprawling, swollen towns beyond \n",
      "ohio,   interminable inquisitions  spar', Perplexity score :: 0.17\n",
      "Prompt 9: '    trouble,  see.”\n",
      "\n",
      "“how   day  tomorrow?”\n",
      "\n",
      "he considered   moment. then,  reluctance: “i want  get', Perplexity score :: 0.17\n",
      "Prompt 10: 'r. sloane   lady walked   steps  mounted\n",
      " horses.\n",
      "\n",
      "“come ,” said mr. sloane  tom, “’ late. we’ got  ', Perplexity score :: 0.17\n",
      "Average Perplexity score :: 0.17\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# load model and character mappings\n",
    "#loading a pre-trained PyTorch model and a dictionary that maps each character to an integer index. \n",
    "#It also calculates the number of unique characters in the dataset and creates a dictionary that maps integer indices back to their corresponding characters.\n",
    "\n",
    "best_model, char_to_int = torch.load(\"singlebest-char.pth\")\n",
    "n_vocab = len(char_to_int)\n",
    "int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    "\n",
    "# load text data\n",
    "filename = \"thegreatgatsby_clean.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# compute perplexity for each generated prompt\n",
    "perplexities = []\n",
    "for j in range(10):\n",
    "    # randomly generate a prompt\n",
    "    seq_length = 100\n",
    "    start = np.random.randint(0, len(raw_text)-seq_length)\n",
    "    prompt = raw_text[start:start+seq_length]\n",
    "    pattern = [char_to_int[c] for c in prompt]\n",
    "\n",
    "    # load best model parameters and set to evaluation mode\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    # compute log-likelihood of each character in generated text\n",
    "    log_likelihoods = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1000):\n",
    "            # format input array of int into PyTorch tensor\n",
    "            x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "            # generate logits as output from the model\n",
    "            prediction = model(x)\n",
    "            # convert logits into one character\n",
    "            index = int(prediction.argmax())\n",
    "            result = int_to_char[index]\n",
    "            # compute log-likelihood of the predicted character\n",
    "            log_likelihood = np.log(prediction[0, index].item())\n",
    "            log_likelihoods.append(log_likelihood)\n",
    "            # append the new character into the prompt for the next iteration\n",
    "            pattern.append(index)\n",
    "            pattern = pattern[1:]\n",
    "\n",
    "    # compute perplexity of generated text\n",
    "    avg_log_likelihood = np.mean(log_likelihoods)\n",
    "    perplexity = np.exp(-avg_log_likelihood)\n",
    "    perplexities.append(perplexity)\n",
    "    print(f\"Prompt {j+1}: '{prompt}', Perplexity score :: {perplexity:.2f}\")\n",
    "\n",
    "# compute average perplexity over all generated prompts\n",
    "avg_perplexity = np.mean(perplexities)\n",
    "print(f\"Average Perplexity score :: {avg_perplexity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8806993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1abcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee94dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
